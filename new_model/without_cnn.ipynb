{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import ipyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"../Data\")\n",
    "train_data_path = os.path.join(data_path, \"asl_alphabet_train/asl_alphabet_train\")\n",
    "test_data_path = os.path.join(data_path, \"asl_alphabet_test/asl_alphabet_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_draw = mp.solutions.download_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "img_size = 32\n",
    "array_value = list()\n",
    "count = -1\n",
    "\n",
    "for class_names in os.listdir(test_data_path):\n",
    "    count += 1\n",
    "    array_value.append(np.zeros((200,200)))\n",
    "    class_path = os.path.join(test_data_path, class_names)\n",
    "    for image_name in os.listdir(class_path):\n",
    "        img = cv2.imread(os.path.join(class_path, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        results = hands.process(cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            h, w, _ = img_rgb.shape\n",
    "            \n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    x = int(lm.x * w)\n",
    "                    y = int(lm.y * h)\n",
    "                    \n",
    "                    array_value[count][y][x] = 1\n",
    "                    cv2.circle(img_rgb, (x, y), 1, (0, 255, 0), -1)\n",
    "            \n",
    "        \n",
    "print(np.sum(array_value[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m             labels\u001b[38;5;241m.\u001b[39mappend(class_name)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(images), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[1;32m---> 15\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m, in \u001b[0;36mload_images\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m class_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, class_name)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(class_path):\n\u001b[1;32m----> 7\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[0;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (img_size, img_size))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load_images(data_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for class_name in os.listdir(data_path):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            img = cv2.imread(os.path.join(class_path, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "            plt.imshow(img)\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            img = img / 255.0\n",
    "            images.append(img)\n",
    "            labels.append(class_name)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X, y = load_images(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78000, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(image, kernel):\n",
    "    h, w = image.shape\n",
    "    kh, kw = kernel.shape\n",
    "    output = np.zeros((h - kh + 1, w - kw + 1))\n",
    "\n",
    "    for i in range(h - kh + 1):\n",
    "        for j in range(w - kw + 1):\n",
    "            output[i, j] = np.sum(image[i:i+kh, j:j+kw] * kernel)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(image, size=2, stride=2):\n",
    "    h, w = image.shape\n",
    "    output_h = (h - size) // stride + 1\n",
    "    output_w = (w - size) // stride + 1\n",
    "    pooled = np.zeros((output_h, output_w))\n",
    "\n",
    "    for i in range(0, h - size + 1, stride):\n",
    "        for j in range(0, w - size + 1, stride):\n",
    "            pooled[i//stride, j//stride] = np.max(image[i:i+size, j:j+size])\n",
    "\n",
    "    return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / exp_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_layer(flattened_input, weights, biases):\n",
    "    return softmax(np.dot(flattened_input, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(image, conv_filter, fc_weights, fc_biases):\n",
    "    conv_output = conv2d(image, conv_filter)\n",
    "    conv_output = relu(conv_output)\n",
    "\n",
    "    pooled_output = max_pooling(conv_output)\n",
    "\n",
    "    flattened = pooled_output.flatten()\n",
    "\n",
    "    output = fully_connected_layer(flattened, fc_weights, fc_biases)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_filter:  [[-2.01014735  1.08001725  0.88481771]\n",
      " [ 2.43104581 -0.62850344 -0.61230199]\n",
      " [-0.78293833  0.18697731  2.20280523]]\n",
      "fc_weights:  [[-2.14598832  0.05075141 -0.74488799 ... -0.75301928  1.27031607\n",
      "  -0.71764105]\n",
      " [ 0.9304432   0.34991896  0.40202498 ... -0.02415371  0.55419188\n",
      "  -0.9353328 ]\n",
      " [-2.16179733 -0.2186046  -0.33608412 ...  1.23067231 -1.46921082\n",
      "   0.36264965]\n",
      " ...\n",
      " [ 0.59939567  0.83651017 -0.5421115  ...  0.9141237   0.47452981\n",
      "  -0.50173117]\n",
      " [ 0.78187692  1.13244268  2.64217854 ... -0.22204995  0.57783624\n",
      "  -2.61830318]\n",
      " [ 0.38281497  2.47241814  0.10218848 ... -0.30364843 -1.0711663\n",
      "  -1.32767867]]\n",
      "fc_biases:  [-0.23546092  1.19163136 -0.95239302  0.81613642  1.83626114  0.26098409\n",
      " -0.01271884  0.09700358 -0.64710917 -0.77557437 -0.05571881 -0.14608024\n",
      " -0.8819245  -1.56672708  0.55238811 -1.39075298  0.50819919 -1.12743502\n",
      "  0.06908873  1.1110826  -0.93041405 -0.67314399  0.88235817  1.42337148\n",
      " -0.23363341  0.39639979]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (225,) and (64,26) not aligned: 225 (dim 0) != 64 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m             fc_biases \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m fc_grad\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X_train, y_train, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train)):\n\u001b[1;32m---> 13\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_biases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(output[y_train[i]])\n\u001b[0;32m     15\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36mforward_propagation\u001b[1;34m(image, conv_filter, fc_weights, fc_biases)\u001b[0m\n\u001b[0;32m      5\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m max_pooling(conv_output)\n\u001b[0;32m      7\u001b[0m flattened \u001b[38;5;241m=\u001b[39m pooled_output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfully_connected_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc_biases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m, in \u001b[0;36mfully_connected_layer\u001b[1;34m(flattened_input, weights, biases)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfully_connected_layer\u001b[39m(flattened_input, weights, biases):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m softmax(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m biases)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (225,) and (64,26) not aligned: 225 (dim 0) != 64 (dim 0)"
     ]
    }
   ],
   "source": [
    "def train(X_train, y_train, learning_rate=0.01, epochs=10):\n",
    "    conv_filter = np.random.randn(3, 3)\n",
    "    fc_weights = np.random.randn(64, 26)\n",
    "    fc_biases = np.random.randn(26)\n",
    "    \n",
    "    print(\"conv_filter: \", conv_filter)\n",
    "    print(\"fc_weights: \", fc_weights)\n",
    "    print(\"fc_biases: \", fc_biases)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(len(X_train)):\n",
    "            output = forward_propagation(X_train[i], conv_filter, fc_weights, fc_biases)\n",
    "            loss = -np.log(output[y_train[i]])\n",
    "            total_loss += loss\n",
    "\n",
    "            fc_grad = output\n",
    "            fc_grad[y_train[i]] -= 1\n",
    "            fc_weights -= learning_rate * np.outer(fc_grad, X_train[i].flatten())\n",
    "            fc_biases -= learning_rate * fc_grad\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss}\")\n",
    "\n",
    "train(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
